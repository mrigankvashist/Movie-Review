{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-11-07T10:15:06.454692Z",
     "iopub.status.busy": "2021-11-07T10:15:06.453928Z",
     "iopub.status.idle": "2021-11-07T10:15:06.492218Z",
     "shell.execute_reply": "2021-11-07T10:15:06.491539Z",
     "shell.execute_reply.started": "2021-11-07T10:15:06.454574Z"
    }
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T10:15:22.647898Z",
     "iopub.status.busy": "2021-11-07T10:15:22.647557Z",
     "iopub.status.idle": "2021-11-07T10:15:24.392703Z",
     "shell.execute_reply": "2021-11-07T10:15:24.391720Z",
     "shell.execute_reply.started": "2021-11-07T10:15:22.647862Z"
    }
   },
   "outputs": [],
   "source": [
    "#importing data\n",
    "df = pd.read_csv(\"/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv\")\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T10:15:42.478652Z",
     "iopub.status.busy": "2021-11-07T10:15:42.477953Z",
     "iopub.status.idle": "2021-11-07T10:15:42.642673Z",
     "shell.execute_reply": "2021-11-07T10:15:42.641862Z",
     "shell.execute_reply.started": "2021-11-07T10:15:42.478609Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Summary statistics of numerical features : \\n\", df.describe())\n",
    "\n",
    "print(\"=======================================================================\")\n",
    "\n",
    "print(\"\\nTotal number of reviews: \",len(df))\n",
    "\n",
    "print(\"=======================================================================\")\n",
    "\n",
    "print(\"\\nTotal number of Sentiments: \", len(list(set(df['sentiment']))))\n",
    "\n",
    "df['sentiment'] = np.where(df['sentiment'] == \"positive\", 1, 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T10:16:53.663008Z",
     "iopub.status.busy": "2021-11-07T10:16:53.662679Z",
     "iopub.status.idle": "2021-11-07T10:16:53.689532Z",
     "shell.execute_reply": "2021-11-07T10:16:53.688886Z",
     "shell.execute_reply.started": "2021-11-07T10:16:53.662972Z"
    }
   },
   "outputs": [],
   "source": [
    "#Data prepration\n",
    "\n",
    "df = df.sample(frac=0.1, random_state=0) \n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T10:17:46.389316Z",
     "iopub.status.busy": "2021-11-07T10:17:46.388327Z",
     "iopub.status.idle": "2021-11-07T10:17:47.380692Z",
     "shell.execute_reply": "2021-11-07T10:17:47.379753Z",
     "shell.execute_reply.started": "2021-11-07T10:17:46.389269Z"
    }
   },
   "outputs": [],
   "source": [
    "#train-test split\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['review'], df['sentiment'], \\\n",
    "                                                    test_size=0.1, random_state=0)\n",
    "\n",
    "print('Load %d training examples and %d validation examples. \\n' %(X_train.shape[0],X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T10:18:03.660777Z",
     "iopub.status.busy": "2021-11-07T10:18:03.660470Z",
     "iopub.status.idle": "2021-11-07T10:18:03.670046Z",
     "shell.execute_reply": "2021-11-07T10:18:03.669116Z",
     "shell.execute_reply.started": "2021-11-07T10:18:03.660743Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T10:18:11.497360Z",
     "iopub.status.busy": "2021-11-07T10:18:11.497015Z",
     "iopub.status.idle": "2021-11-07T10:18:11.505938Z",
     "shell.execute_reply": "2021-11-07T10:18:11.504865Z",
     "shell.execute_reply.started": "2021-11-07T10:18:11.497328Z"
    }
   },
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bag of Words\n",
    "\n",
    "\n",
    "Step 1 : Preprocess raw reviews to cleaned reviews\n",
    "\n",
    "Step 2 : Create BoW using CountVectorizer / Tfidfvectorizer in sklearn\n",
    "\n",
    "Step 3 : Transform review text to numerical representations (feature vectors)\n",
    "\n",
    "Step 4 : Fit feature vectors to supervised learning algorithm (eg. Naive Bayes, Logistic regression, etc.)\n",
    "\n",
    "Step 5 : Improve the model performance by GridSearch\n",
    "\n",
    "Text Preprocessing\n",
    "\n",
    "\n",
    "Step 1 : remove html tags using BeautifulSoup\n",
    "\n",
    "Step 2 : remove non-character such as digits and symbols\n",
    "\n",
    "Step 3 : convert to lower case\n",
    "\n",
    "Step 4 : remove stop words such as \"the\" and \"and\" if needed\n",
    "\n",
    "Step 5 : convert to root words by stemming if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T10:21:24.313736Z",
     "iopub.status.busy": "2021-11-07T10:21:24.312276Z",
     "iopub.status.idle": "2021-11-07T10:21:24.325605Z",
     "shell.execute_reply": "2021-11-07T10:21:24.324491Z",
     "shell.execute_reply.started": "2021-11-07T10:21:24.313678Z"
    }
   },
   "outputs": [],
   "source": [
    "def cleanText(raw_text, remove_stopwords=False, stemming=False, split_text=False, \\\n",
    "             ):\n",
    "    '''\n",
    "    Convert a raw review to a cleaned review\n",
    "    '''\n",
    "    text = BeautifulSoup(raw_text, 'html.parser').get_text()\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    words = letters_only.lower().split() \n",
    "    \n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        words = [w for w in words if not w in stops]\n",
    "        \n",
    "    if stemming==True:\n",
    "\n",
    "        stemmer = SnowballStemmer('english') \n",
    "        words = [stemmer.stem(w) for w in words]\n",
    "        \n",
    "    if split_text==True:\n",
    "        return (words)\n",
    "    \n",
    "    return( \" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T10:21:50.979561Z",
     "iopub.status.busy": "2021-11-07T10:21:50.979242Z",
     "iopub.status.idle": "2021-11-07T10:21:54.432297Z",
     "shell.execute_reply": "2021-11-07T10:21:54.431545Z",
     "shell.execute_reply.started": "2021-11-07T10:21:50.979530Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import SnowballStemmer, WordNetLemmatizer\n",
    "from nltk import sent_tokenize, word_tokenize, pos_tag\n",
    "from bs4 import BeautifulSoup \n",
    "import logging\n",
    "from wordcloud import WordCloud\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "\n",
    "X_train_cleaned = []\n",
    "X_test_cleaned = []\n",
    "\n",
    "for d in X_train:\n",
    "    X_train_cleaned.append(cleanText(d))\n",
    "    \n",
    "for d in X_test:\n",
    "    X_test_cleaned.append(cleanText(d))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CountVectorizer with Mulinomial Naive Bayes (Benchmark Model)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T10:23:01.592645Z",
     "iopub.status.busy": "2021-11-07T10:23:01.591693Z",
     "iopub.status.idle": "2021-11-07T10:23:03.041154Z",
     "shell.execute_reply": "2021-11-07T10:23:03.040199Z",
     "shell.execute_reply.started": "2021-11-07T10:23:01.592592Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "countVect = CountVectorizer() \n",
    "X_train_countVect = countVect.fit_transform(X_train_cleaned)\n",
    "print(\"Number of features : %d \\n\" %len(countVect.get_feature_names())) #6378 \n",
    "print(\"Show some feature names : \\n\", countVect.get_feature_names()[::1000])\n",
    "\n",
    "\n",
    "# Train MultinomialNB classifier\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_countVect, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T10:23:25.997001Z",
     "iopub.status.busy": "2021-11-07T10:23:25.996324Z",
     "iopub.status.idle": "2021-11-07T10:23:26.014917Z",
     "shell.execute_reply": "2021-11-07T10:23:26.014047Z",
     "shell.execute_reply.started": "2021-11-07T10:23:25.996947Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(countVect,open('countVect_imdb.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T10:24:01.108587Z",
     "iopub.status.busy": "2021-11-07T10:24:01.108305Z",
     "iopub.status.idle": "2021-11-07T10:24:01.115448Z",
     "shell.execute_reply": "2021-11-07T10:24:01.114247Z",
     "shell.execute_reply.started": "2021-11-07T10:24:01.108557Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "def modelEvaluation(predictions):\n",
    "    '''\n",
    "    Print model evaluation to predicted result \n",
    "    '''\n",
    "    print (\"\\nAccuracy on validation set: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
    "    print(\"\\nAUC score : {:.4f}\".format(roc_auc_score(y_test, predictions)))\n",
    "    print(\"\\nClassification report : \\n\", metrics.classification_report(y_test, predictions))\n",
    "    print(\"\\nConfusion Matrix : \\n\", metrics.confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T10:24:09.968177Z",
     "iopub.status.busy": "2021-11-07T10:24:09.967608Z",
     "iopub.status.idle": "2021-11-07T10:24:10.118375Z",
     "shell.execute_reply": "2021-11-07T10:24:10.117397Z",
     "shell.execute_reply.started": "2021-11-07T10:24:09.968136Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = mnb.predict(countVect.transform(X_test_cleaned))\n",
    "modelEvaluation(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-11-07T10:26:01.831683Z",
     "iopub.status.busy": "2021-11-07T10:26:01.831391Z",
     "iopub.status.idle": "2021-11-07T10:26:01.838502Z",
     "shell.execute_reply": "2021-11-07T10:26:01.837587Z",
     "shell.execute_reply.started": "2021-11-07T10:26:01.831648Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(mnb,open('Naive_Bayes_model_imdb.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
